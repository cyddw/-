## 参考文献：[CSDN](https://blog.csdn.net/xys430381_1/article/details/110456496)、[CSDN](https://blog.csdn.net/oTengYue/article/details/89644170)

## 什么是惩罚(正则化)

我们经常看到，标准损失函数通常由两项组成，**数据损失项和惩罚项**，并将惩罚项乘以超参数λ，用来平衡这两项。

其中惩罚项的作用就是**防止模型过拟合，提高模型的泛化能力**

> <img width="299" alt="image" src="https://github.com/user-attachments/assets/86360bc2-67dd-4373-9cd5-3188d9760d24">

其中，第一项是Loss Function，我们希望其尽可能小；第二项是Penalty Term，我们也希望其尽可能小(因为其越小，说明该模型越简单)

由于Penalty Term代表模型复杂度，因此其一般是**模型复杂度的单调递增函数**，例如：

> <img width="579" alt="image" src="https://github.com/user-attachments/assets/1d30d152-de46-4eac-b81e-e1a83b170f8c">

## L0、L1和L2范数

+ L0范数：向量中非0元素的个数

> L0范数惩罚可以做到稀疏，但是由于其很难优化求解，且L1范数是L0范数的最优凸近似，因此一般适用L1范数代替L0范数

+ L1范数：向量中各个元素绝对值之和

> L1范数惩罚，也称为参数稀疏性惩罚，稀疏性所带来的好处：一般来说，xi的大部分元素（也就是特征）都是和最终的输出yi没有关系或者不提供任何信息的，在最小化目标函数的时候考虑xi这些额外的特征，虽然可以获得更小的训练误差，但在预测新的样本时，这些没用的信息反而会被考虑，从而干扰了对正确yi的预测。稀疏规则化算子的引入就是为了完成特征自动选择的光荣使命，它会学习地去掉这些没有信息的特征，也就是把这些特征对应的权重置为0。

+ L2范数：向量元素绝对值的平方和再开平方

> 对于L2范数惩罚而言，虽然也能防止过拟合，但其没有稀疏性，也就是说L2范数只能让权重趋于0，而不是等于0
